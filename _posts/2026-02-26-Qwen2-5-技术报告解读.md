---
layout: post
title: "Qwen2.5 技术报告深度解读"
date: 2026-02-26 23:28:00 +0800
categories: paper-reading qwen llm
---

## 论文基本信息

> **论文**: Qwen2.5 Technical Report  
> **arXiv**: [2412.15115](https://arxiv.org/abs/2412.15115)  
> **发布时间**: 2024年12月19日  
> **作者**: Qwen团队（An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui等）

---

## 1. 预训练数据规模

### 数据量级跃升
| 版本 | 预训练数据规模 |
|------|--------------|
| Qwen2 | 7万亿 tokens |
| **Qwen2.5** | **18万亿 tokens** |
| 增长幅度 | **2.57倍** |

### 数据质量提升四大措施

**(1) 更好的数据过滤**
- 利用 **Qwen2-Instruct** 模型作为数据质量过滤器
- 多维度综合评分机制，替代Qwen2的简单过滤方法

**(2) 更优的数学与代码数据**
- 整合了 **Qwen2.5-Math** 和 **Qwen2.5-Coder** 的训练数据
- 在专业数学推理和代码生成任务上达到SOTA性能

**(3) 更高质量的合成数据**
- 利用 **Qwen2-72B-Instruct** 和 **Qwen2-Math-72B-Instruct** 生成合成数据
- 通过通用奖励模型和 **Qwen2-Math-RM-72B** 进行严格过滤

**(4) 更好的数据混合策略**
- 使用Qwen2-Instruct模型对不同领域内容进行分类和平衡
- **降采样**：电商、社交媒体、娱乐等过度代表的领域
- **升采样**：科技、科学、学术研究等高价值领域

---

## 2. 模型架构优化

### 基础架构（Dense模型）
Qwen2.5保持了与Qwen2相同的Transformer解码器架构，核心组件包括：

| 组件 | 技术 |
|------|------|
| 注意力机制 | Grouped Query Attention (GQA) |
| 激活函数 | SwiGLU |
| 位置编码 | Rotary Positional Embeddings (RoPE) |
| 归一化 | RMSNorm + Pre-normalization |
| 注意力偏置 | QKV bias |

### MoE架构扩展（API服务模型）
- **Qwen2.5-Turbo** 和 **Qwen2.5-Plus** 采用混合专家架构
- 替换标准FFN层为MoE层，包含多个FFN专家和路由机制
- 实现 **细粒度专家分割** (Fine-grained Expert Segmentation)
- **共享专家路由** (Shared Experts Routing)

### 模型规模配置

| 模型 | 参数量 | 层数 | 头数(Q/KV) | 上下文长度 |
|------|--------|------|-----------|-----------|
| Qwen2.5-0.5B | 0.5B | 24 | 14/2 | 32K/8K |
| Qwen2.5-1.5B | 1.5B | 28 | 12/2 | 32K/8K |
| Qwen2.5-3B | 3B | 36 | 16/2 | 32K/8K |
| Qwen2.5-7B | 7B | 28 | 28/4 | 128K/8K |
| Qwen2.5-14B | 14B | 48 | 40/8 | 128K/8K |
| Qwen2.5-32B | 32B | 64 | 40/8 | 128K/8K |
| Qwen2.5-72B | 72B | 80 | 64/8 | 128K/8K |

---

## 3. 指令遵循能力

### SFT数据规模
- **超过100万个高质量样本**（相比Qwen2大幅提升）
- 序列长度：32,768 tokens
- 训练轮次：2个epoch

### 八大关键增强领域

| 领域 | 具体改进 |
|------|---------|
| **长序列生成** | 输出长度从2K扩展到**8K tokens** |
| **数学推理** | 引入Qwen2.5-Math的思维链数据 |
| **代码能力** | 整合Qwen2.5-Coder指令数据 |
| **指令遵循** | 基于代码验证的严格筛选框架 |
| **结构化数据理解** | 表格问答、事实验证、错误修正 |
| **逻辑推理** | 70,000个多样化查询 |
| **跨语言迁移** | 高资源语言向低资源语言迁移 |
| **系统指令鲁棒性** | 数百个通用系统提示 |

### 两阶段强化学习

**Stage 1: Offline RL (DPO)**
- 专注于难以用奖励模型评估的能力
- 推理、事实性、指令遵循
- 约150,000训练对

**Stage 2: Online RL (GRPO)**
- 利用奖励模型检测输出质量细微差别
- 真实性、有用性、简洁性、相关性、无害性、去偏见
- 每组查询采样8个响应

---

## 4. 工具使用能力

### Function Calling改进
- 新增**2个专门的工具功能token**
- 更好的**结构化输入输出支持**（表格、JSON）
- 更易于使用的工具调用接口

### 长上下文能力（工具使用场景）

| 模型 | 上下文长度 | 技术方案 |
|------|-----------|---------|
| Qwen2.5-Turbo | **1百万 tokens** | YARN + DCA + 稀疏注意力 |
| 其他模型 | 131,072 tokens | YARN + DCA |

---

## 5. 专业模型系列

Qwen2.5作为基础模型，支撑了多个专业领域的衍生模型：

| 专业模型 | 领域 | 关键特性 |
|---------|------|---------|
| **Qwen2.5-Math** | 数学推理 | 自我改进、思维链、SOTA数学能力 |
| **Qwen2.5-Coder** | 代码生成 | 40种编程语言、多智能体协作 |
| **QwQ** | 推理探索 | 深度思考、边界探索 |
| **多模态模型** | 视觉-语言 | 统一框架处理文本、视觉、音频 |

---

## 6. 性能对比

### 6.1 与Qwen2对比（72B模型）

| 基准测试 | Qwen2-72B | Qwen2.5-72B | 提升 |
|---------|-----------|-------------|------|
| MMLU | 84.2 | **86.1** | +1.9 |
| MMLU-Pro | 55.7 | **58.1** | +2.4 |
| BBH | 82.4 | **86.3** | +3.9 |
| MATH | 50.9 | **62.1** | +11.2 |
| GSM8K | 89.0 | **91.5** | +2.5 |
| HumanEval | 64.6 | 59.1 | -5.5 |
| MBPP | 76.9 | **84.7** | +7.8 |

### 6.2 与Llama系列对比

**Qwen2.5-72B vs Llama-3-405B**（5倍参数量差距）

| 基准测试 | Llama-3-405B | Qwen2.5-72B | 优势 |
|---------|--------------|-------------|------|
| MMLU | 85.2 | 86.1 | ✅ |
| MATH | 53.8 | **62.1** | ✅ +8.3 |
| GSM8K | 89.0 | 91.5 | ✅ |
| HumanEval | 61.0 | 59.1 | - |
| MBPP | 73.0 | **84.7** | ✅ +11.7 |

**结论**：Qwen2.5-72B以**1/5的参数量**达到或超越Llama-3-405B

### 6.3 与GPT系列对比（MoE模型）

| 模型 | 对比对象 | 表现 |
|------|---------|------|
| Qwen2.5-Turbo | GPT-4o-mini | **相当性能，显著更低成本** |
| Qwen2.5-Plus | GPT-4o | **相当性能** |

---

## 总结

Qwen2.5作为"全面增强版"的核心改进：

| 维度 | Qwen2.5亮点 |
|------|-------------|
| **数据规模** | 7T → 18T tokens (2.57×) |
| **架构覆盖** | 0.5B-72B Dense + MoE变体 |
| **生成能力** | 2K → 8K 输出长度 |
| **上下文窗口** | 128K标准 / 1M (Turbo) |
| **指令遵循** | 100万+ SFT样本 + 两阶段RL |
| **工具使用** | 结构化IO + Function Calling增强 |
| **数学推理** | SOTA性能 (MATH: 83.1) |
| **代码生成** | 40种语言支持 |
| **多语言能力** | 122种语言变体 |

Qwen2.5标志着开源大模型进入"全面增强"新阶段：在保持开源生态开放性的同时，通过数据质量提升、训练方法创新和架构优化，实现了与顶级闭源模型相媲美的性能表现。
