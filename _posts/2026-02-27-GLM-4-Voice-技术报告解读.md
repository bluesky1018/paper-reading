---
layout: post
title: "GLM-4-Voice 技术报告深度解读"
date: 2026-02-27 00:25:00 +0800
categories: paper-reading chatglm glm zhipu voice multimodal
---

## 论文基本信息

> **论文**: GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot  
> **arXiv**: [2412.02612](https://arxiv.org/abs/2412.02612)  
> **发布时间**: 2024年12月3日  
> **作者**: Aohan Zeng等 (智谱AI团队)

---

## 1. 概述

GLM-4-Voice是智谱AI发布的**端到端语音对话模型**，能够直接理解和生成中英文语音，支持实时语音对话，并可根据用户指令调整情感、语调、语速和方言等声音属性。

---

## 2. 核心创新

### 2.1 端到端语音建模

不同于传统的级联系统（ASR→LLM→TTS），GLM-4-Voice采用**端到端架构**：

```
语音输入 → GLM-4-Voice → 语音输出
    ↓
无需文本中间表示
```

### 2.2 超低保真语音Tokenizer

| 特性 | 详情 |
|------|------|
| **比特率** | **175 bps** (超低) |
| **码本** | 单码本 (single-codebook) |
| **帧率** | 12.5 Hz |
| **来源** | 基于ASR模型改造的VQ编码器 |

**技术实现**:
- 在ASR编码器中加入向量量化(Vector-Quantized)瓶颈
- 高效的语音离散化表示

---

## 3. 训练流程

### 3.1 数据准备

**语音-文本交错数据合成**:
- 使用文本预训练语料
- 通过text-to-token模型合成语音token
- 创建大规模语音-文本交错数据

### 3.2 三阶段训练

```
阶段1: 继续预训练
├── 基础模型: GLM-4-9B
├── 数据: 1万亿 tokens
├── 数据类型:
│   ├── 无监督语音数据
│   ├── 语音-文本交错数据
│   └── 监督语音-文本数据
└── 目标: 语音语言建模

阶段2: 语音问答训练
├── 任务: 语音问答
└── 目标: 理解并回答语音问题

阶段3: 对话微调
├── 数据: 高质量对话语音数据
├── 目标: 对话能力和语音质量
└── 结果: 超越现有基线
```

---

## 4. 模型能力

### 4.1 核心功能

| 功能 | 描述 |
|------|------|
| **实时对话** | 支持中英文实时语音对话 |
| **情感控制** | 根据指令调整情感表达 |
| **语调变化** | 支持多种语调风格 |
| **语速调节** | 可快可慢，灵活控制 |
| **方言支持** | 支持中英文方言 |
| **语音问答** | 直接回答语音问题 |

### 4.2 性能表现

GLM-4-Voice在以下方面达到**SOTA**:
- 语音语言建模
- 语音问答
- 对话能力
- 语音质量

---

## 5. 技术架构

### 5.1 模型参数

| 参数 | 配置 |
|------|------|
| **基础模型** | GLM-4-9B |
| **训练数据** | 1万亿 tokens |
| **支持语言** | 中文、英文 |

### 5.2 系统架构

```
用户语音输入
    ↓
语音Tokenizer (175bps, 12.5Hz)
    ↓
GLM-4-Voice (9B参数)
    ↓
语音Token输出
    ↓
语音解码器
    ↓
用户语音输出
```

---

## 6. 开源贡献

### 6.1 开源内容

| 资源 | 链接 |
|------|------|
| **模型权重** | Hugging Face: THUDM/glm-4-voice-9b |
| **代码** | GitHub: THUDM/GLM-4-Voice |
| **演示** | 在线Demo |

### 6.2 与Qwen2.5-Omni对比

| 特性 | GLM-4-Voice | Qwen2.5-Omni |
|------|-------------|--------------|
| **架构** | 端到端语音 | Thinker-Talker |
| **Tokenizer** | 175bps单码本 | - |
| **多模态** | 语音 | 语音+图像+视频 |
| **情感控制** | ✅ 支持 | ✅ 支持 |
| **实时性** | ✅ 实时 | ✅ 流式 |
| **开源** | ✅ 完全开源 | ✅ 开源 |

---

## 7. 应用场景

### 7.1 实时语音助手

- 智能客服
- 语音陪伴
- 实时翻译

### 7.2 情感化交互

- 有情感的语音助手
- 个性化语音合成
- 角色扮演

### 7.3 多语言应用

- 中英文双语对话
- 方言支持
- 跨语言交流

---

## 总结

GLM-4-Voice作为智谱AI的端到端语音模型，具有以下核心价值：

1. **端到端架构**: 直接语音输入输出，无需文本中间表示
2. **超低保真Tokenizer**: 175bps单码本，高效压缩
3. **情感可控**: 支持情感、语调、语速、方言调节
4. **SOTA性能**: 语音语言建模和问答领先
5. **完全开源**: 模型、代码全部公开

GLM-4-Voice代表了端到端语音对话模型的重要进步，为构建更自然、更人性化的语音交互系统提供了强大基础。
