---
layout: post
title: "ChatGLM/GLM系列全版本综合对比分析"
date: 2026-02-27 00:25:00 +0800
categories: paper-reading chatglm glm zhipu comparison
---

## 论文基本信息

> **对比对象**: GLM-130B / ChatGLM-6B系列 / GLM-4系列 / GLM-4V / GLM-4-Voice  
> **分析范围**: 2022年10月 - 2024年12月  
> **数据来源**: 各版本技术报告、官方资料

---

## 1. 版本演进时间线

```
2022.10      2023.03      2023.06      2023.10      2024.06      2024.12
   │            │            │            │            │            │
   ▼            ▼            ▼            ▼            ▼            ▼
GLM-130B → ChatGLM-6B → ChatGLM2-6B → ChatGLM3-6B → GLM-4系列 → GLM-4-Voice
(开源130B)   (首代6B)    (32K上下文)   (工具调用)   (10T数据)   (端到端语音)
                              ↓
                         GLM-4V-9B (2024.06)
                         (视觉语言)
```

---

## 2. 核心参数对比

### 2.1 基础模型对比

| 版本 | 参数量 | 上下文 | 训练数据 | 核心特点 |
|------|--------|--------|----------|----------|
| **GLM-130B** | 130B | 2K | ~400B tokens | 首个开源双语100B+ |
| **ChatGLM-6B** | 6B | 2K/8K | - | 首代对话模型 |
| **ChatGLM2-6B** | 6B | 32K | - | FlashAttention |
| **ChatGLM3-6B** | 6B | 8K/32K | - | 基础模型+工具 |
| **GLM-4** | 未公开 | 128K | **10T tokens** | 对标GPT-4 |
| **GLM-4-9B** | 9B | 128K/1M | 10T tokens | 开源旗舰 |
| **GLM-4V-9B** | 9B | 8K | - | 视觉语言 |
| **GLM-4-Voice** | 9B | - | 1T tokens | 端到端语音 |

### 2.2 架构演进

| 版本 | 架构 | 注意力 | 位置编码 |
|------|------|--------|----------|
| **GLM-130B** | GLM | 双向+自回归 | 标准 |
| **ChatGLM系列** | GLM | 优化注意力 | 旋转位置编码 |
| **GLM-4系列** | 改进GLM | FlashAttention | RoPE |
| **GLM-4V** | GLM+ViT | 多模态 | 统一编码 |
| **GLM-4-Voice** | GLM+语音 | 端到端 | 语音RoPE |

---

## 3. 能力演进对比

### 3.1 通用能力 (MMLU/GSM8K)

```
GLM-130B:     约45 (MMLU)
    ↓
ChatGLM-6B:   约40
    ↓
ChatGLM3-6B:  约45
    ↓
GLM-4:        约80 (接近GPT-4)
    ↓
GLM-4-9B:     约75
```

### 3.2 长上下文能力

| 版本 | 最大上下文 | 技术 |
|------|-----------|------|
| **GLM-130B** | 2K | 基础 |
| **ChatGLM-6B** | 8K | 扩展 |
| **ChatGLM2-6B** | **32K** | FlashAttention |
| **GLM-4系列** | **128K/1M** | 长上下文优化 |

### 3.3 多模态能力

| 版本 | 视觉 | 语音 | 文本 | 工具 |
|------|------|------|------|------|
| **GLM-130B** | ❌ | ❌ | ✅ | ❌ |
| **ChatGLM系列** | ❌ | ❌ | ✅ | 部分 |
| **GLM-4V** | ✅ | ❌ | ✅ | ✅ |
| **GLM-4-Voice** | ❌ | ✅ | ✅ | ❌ |
| **GLM-4 All Tools** | ✅ | ✅ | ✅ | ✅ |

---

## 4. 开源策略对比

### 4.1 开源模型矩阵

| 模型 | 开源时间 | 许可证 | 影响力 |
|------|----------|--------|--------|
| **GLM-130B** | 2022.10 | 开源 | 首个100B+开源双语 |
| **ChatGLM-6B** | 2023.03 | 开源 | HuggingFace热门 |
| **ChatGLM2-6B** | 2023.06 | 开源 | 长上下文热门 |
| **ChatGLM3-6B** | 2023.10 | 开源 | 工具调用 |
| **GLM-4-9B** | 2024.06 | **可商用** | 最新开源 |
| **GLM-4V-9B** | 2024.06 | 可商用 | 视觉开源 |
| **CodeGeeX** | 持续 | 开源 | 代码生成 |

### 4.2 与Qwen开源对比

| 维度 | ChatGLM/GLM | Qwen |
|------|-------------|------|
| **首个开源** | GLM-130B (2022.10) | Qwen (2023.09) |
| **最大开源** | GLM-130B (130B) | Qwen2.5-72B (72B) |
| **视觉开源** | GLM-4V-9B | Qwen2.5-VL |
| **语音开源** | GLM-4-Voice | Qwen2.5-Omni |
| **长上下文** | 128K/1M | 128K/1M |

---

## 5. 技术特色对比

### 5.1 ChatGLM/GLM vs Qwen

| 特性 | ChatGLM/GLM | Qwen |
|------|-------------|------|
| **架构基础** | GLM (双向+自回归) | Transformer Decoder |
| **中文优化** | ✅ 清华KEG背景 | ✅ 阿里达摩院 |
| **首个100B+** | ✅ GLM-130B (2022) | ❌ |
| **动态分辨率** | ❌ | ✅ Qwen2-VL+ |
| **双模式** | ❌ | ✅ Qwen3 |
| **端到端语音** | ✅ GLM-4-Voice | ✅ Qwen2.5-Omni |
| **MoE架构** | ❌ | ✅ Qwen2.5+ |

### 5.2 各自优势

**ChatGLM/GLM优势**:
- 更早的开源（2022年）
- GLM架构创新（双向+自回归）
- 清华KEG学术背景
- CodeGeeX代码生成生态

**Qwen优势**:
- 更快的迭代速度
- 动态分辨率创新
- MoE架构领先
- 更大的开源模型（72B）

---

## 6. 应用场景演进

### 6.1 从通用到专业

```
GLM-130B:    通用语言模型
    ↓
ChatGLM-6B:  对话助手
    ↓
ChatGLM3-6B: 工具使用
    ↓
GLM-4:       全能助手 (对标GPT-4)
    ↓
GLM-4V:      视觉理解
GLM-4-Voice: 语音交互
```

### 6.2 垂直领域应用

| 领域 | 对应模型 | 应用 |
|------|----------|------|
| **代码生成** | CodeGeeX | 编程助手 |
| **网页增强** | WebGLM | 搜索增强 |
| **视觉理解** | GLM-4V | 文档智能 |
| **语音交互** | GLM-4-Voice | 语音助手 |

---

## 7. 版本定位分析

### 7.1 各版本核心定位

| 版本 | 定位 | 历史意义 |
|------|------|----------|
| **GLM-130B** | 开创者 | 中国首个开源100B+模型 |
| **ChatGLM-6B** | 普及者 | 让大模型平民化 |
| **ChatGLM2-6B** | 优化者 | 长上下文突破 |
| **ChatGLM3-6B** | 实用者 | 工具调用能力 |
| **GLM-4** | 追赶者 | 对标GPT-4 |
| **GLM-4-9B** | 开源先锋 | 最新开源可商用 |
| **GLM-4V** | 多模态探索 | 视觉理解 |
| **GLM-4-Voice** | 端到端创新 | 原生语音交互 |

---

## 总结

ChatGLM/GLM系列展现了中国大模型的另一条技术路线：

### 核心成就

1. **开源先驱**: GLM-130B是中国首个开源100B+模型
2. **架构创新**: GLM架构（双向+自回归）独特路线
3. **学术背景**: 清华KEG实验室的技术积累
4. **完整生态**: 文本+代码+视觉+语音全覆盖
5. **持续开源**: 从2022年持续开源至今

### 技术路线对比

- **ChatGLM/GLM**: 学术驱动，GLM架构，稳健迭代
- **Qwen**: 工程驱动，Transformer架构，快速迭代

两条路线各有优势，共同推动了中国大模型技术的发展。
