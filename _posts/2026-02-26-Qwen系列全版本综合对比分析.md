---
layout: post
title: "Qwen系列全版本综合对比分析"
date: 2026-02-26 23:45:00 +0800
categories: paper-reading qwen llm comparison
---

## 论文基本信息

> **对比对象**: Qwen1 / Qwen1.5 / Qwen2 / Qwen2.5 / Qwen3 / Qwen3.5  
> **分析范围**: 2023年9月 - 2026年2月  
> **数据来源**: 各版本技术报告、官方博客、Hugging Face模型卡

---

## 1. 版本演进时间线

```
2023.09        2024.02        2024.07        2024.12        2025.05        2026.02
  │              │              │              │              │              │
  ▼              ▼              ▼              ▼              ▼              ▼
Qwen1  ──────>  Qwen1.5  ────>  Qwen2  ──────>  Qwen2.5  ────>  Qwen3  ──────>  Qwen3.5
(开篇之作)     (迭代优化)      (全面升级)      (全面增强)      (新代旗舰)      (原生多模态)
```

---

## 2. 核心参数对比

### 2.1 训练数据规模

| 版本 | 预训练数据 | 相比前代 | 关键提升 |
|------|-----------|----------|----------|
| **Qwen1** | 3万亿 tokens | - | 基础数据工程 |
| **Qwen1.5** | 3万亿+ (优化) | 质量提升 | 数据清洗优化 |
| **Qwen2** | 7万亿 tokens | **2.3×** | 数据量+质量 |
| **Qwen2.5** | 18万亿 tokens | **2.6×** | 大规模扩展 |
| **Qwen3** | 36万亿 tokens | **2×** | 翻倍增长 |
| **Qwen3.5** | 未公开 | - | 多模态数据 |

### 2.2 上下文长度

| 版本 | 基础长度 | 最大长度 | 技术方案 |
|------|---------|---------|----------|
| **Qwen1** | 2K | 8K (NTK) | 动态NTK |
| **Qwen1.5** | 32K | 32K | 统一扩展 |
| **Qwen2** | 32K | 128K | DCA + YARN |
| **Qwen2.5** | 128K | 1M (Turbo) | 稀疏注意力 |
| **Qwen3** | 128K | 128K | 标准支持 |
| **Qwen3.5** | 262K | 1M | YaRN扩展 |

### 2.3 语言支持

| 版本 | 语言数量 | 重点优化 |
|------|---------|----------|
| **Qwen1** | 100+ | 中英双语 |
| **Qwen1.5** | 12种主要 | 多语言增强 |
| **Qwen2** | ~30种 | 系统性多语言 |
| **Qwen2.5** | 122种 | 广泛覆盖 |
| **Qwen3** | 119种 | 深度学习 |
| **Qwen3.5** | **201种** | 全球部署 |

---

## 3. 架构演进对比

### 3.1 注意力机制演进

| 版本 | 注意力机制 | 创新点 |
|------|-----------|--------|
| **Qwen1** | MHA (标准) | Flash Attention |
| **Qwen1.5** | MHA | 优化实现 |
| **Qwen2** | **GQA** | 分组查询，降低KV缓存 |
| **Qwen2.5** | GQA | 保持优化 |
| **Qwen3** | GQA | 稳定使用 |
| **Qwen3.5** | **Gated DeltaNet** | 线性注意力新架构 |

### 3.2 MoE架构发展

| 版本 | MoE模型 | 专家配置 | 激活比例 |
|------|---------|----------|----------|
| **Qwen1** | ❌ 无 | - | - |
| **Qwen1.5** | ❌ 无 | - | - |
| **Qwen2** | ✅ 57B-A14B | 64+8 | 24.6% |
| **Qwen2.5** | ✅ Turbo/Plus | - | - |
| **Qwen3** | ✅ 235B-A22B | 128 | 9.4% |
| **Qwen3.5** | ✅ 397B-A17B | 256 | 4.3% |

### 3.3 多模态能力

| 版本 | 架构类型 | 视觉支持 | 原生多模态 |
|------|---------|----------|-----------|
| **Qwen1** | 纯文本 | ❌ | ❌ |
| **Qwen1.5** | 纯文本 | ❌ | ❌ |
| **Qwen2** | 纯文本+VL分离 | ✅ (Qwen2-VL) | ❌ |
| **Qwen2.5** | 纯文本+VL分离 | ✅ (Qwen2.5-VL) | ❌ |
| **Qwen3** | 纯文本+VL分离 | ✅ (Qwen3-VL) | ❌ |
| **Qwen3.5** | **原生多模态** | ✅ | ✅ |

---

## 4. 性能对比

### 4.1 旗舰模型MMLU对比

| 版本 | 旗舰模型 | MMLU | MMLU-Pro | 对比说明 |
|------|---------|------|----------|----------|
| **Qwen1** | 72B | ~65 | - | 基础水平 |
| **Qwen1.5** | 72B | ~72 | - | 稳步提升 |
| **Qwen2** | 72B | 84.2 | 55.6 | 大幅跃升 |
| **Qwen2.5** | 72B | 86.1 | 58.1 | 持续优化 |
| **Qwen3** | 235B-A22B | **87.8** | **68.2** | 新高度 |
| **Qwen3.5** | 397B-A17B | - | **83.7** | 多模态优势 |

### 4.2 代码能力演进

| 版本 | HumanEval | LiveCodeBench | 关键突破 |
|------|-----------|---------------|----------|
| **Qwen1** | 37.2 | - | 基础代码 |
| **Qwen1.5** | ~45 | - | 有所提升 |
| **Qwen2** | 64.6 | - | GQA助力 |
| **Qwen2.5** | 59.1 | - | 专业化Coder |
| **Qwen3** | - | 70.7 | Agent能力 |
| **Qwen3.5** | - | 74.6 | 原生Agent |

### 4.3 数学能力演进

| 版本 | MATH | GSM8K | AIME'24 |
|------|------|-------|---------|
| **Qwen1** | ~35 | 61.0 | - |
| **Qwen1.5** | ~45 | ~68 | - |
| **Qwen2** | 51.1 | 89.5 | - |
| **Qwen2.5** | 62.1 | 91.5 | 18.9 |
| **Qwen3** | **71.8** | - | **85.7** |
| **Qwen3.5** | - | - | 89.0 |

---

## 5. 关键特性对比

### 5.1 后训练技术

| 版本 | SFT规模 | RL方法 | 创新点 |
|------|---------|--------|--------|
| **Qwen1** | 数十万 | PPO | 基础RLHF |
| **Qwen1.5** | 数十万 | PPO | 优化流程 |
| **Qwen2** | 50万+ | DPO+Online | 对齐税优化 |
| **Qwen2.5** | **100万+** | DPO+GRPO | 两阶段RL |
| **Qwen3** | 大规模 | 四阶段 | **思考模式融合** |
| **Qwen3.5** | 大规模 | 百万Agent | **可扩展RL** |

### 5.2 输出长度能力

| 版本 | 标准输出 | 最大输出 | 技术 |
|------|---------|---------|------|
| **Qwen1** | 2K | 2K | 基础 |
| **Qwen1.5** | 2K | 2K | 基础 |
| **Qwen2** | 2K | 2K | 基础 |
| **Qwen2.5** | **8K** | **8K** | 扩展训练 |
| **Qwen3** | 8K+ | 8K+ | 思考预算 |
| **Qwen3.5** | 81K | 81K | 超长生成 |

---

## 6. 版本定位分析

### 6.1 各版本核心定位

| 版本 | 定位 | 核心价值 |
|------|------|----------|
| **Qwen1** | 开篇之作 | 证明中国大模型实力，开源生态起步 |
| **Qwen1.5** | 稳健迭代 | 填补空白，积累经验，完善生态 |
| **Qwen2** | 全面升级 | GQA架构、128K上下文、多语言突破 |
| **Qwen2.5** | 全面增强 | 18T数据、8K输出、专业模型系列 |
| **Qwen3** | 新代旗舰 | 双模式统一、MoE高效、推理突破 |
| **Qwen3.5** | 未来方向 | 原生多模态、Agent原生、全球部署 |

### 6.2 技术演进主线

```
数据规模:    3T → 7T → 18T → 36T
              ↓
上下文:      2K → 32K → 128K → 1M
              ↓
架构:        MHA → GQA → Gated DeltaNet
              ↓
多语言:      100+ → 30 → 119 → 201
              ↓
多模态:      分离式 → 原生统一
              ↓
Agent:       工具调用 → 原生Agent
```

---

## 7. 关键里程碑

### 7.1 技术突破里程碑

| 时间 | 版本 | 突破 |
|------|------|------|
| 2023.09 | Qwen1 | **首个开源大模型**，中文领先 |
| 2024.02 | Qwen1.5 | **全尺寸覆盖**，0.5B-72B |
| 2024.07 | Qwen2 | **GQA架构**，128K上下文 |
| 2024.12 | Qwen2.5 | **18T数据**，专业模型系列 |
| 2025.05 | Qwen3 | **双模式统一**，MoE高效 |
| 2026.02 | Qwen3.5 | **原生多模态**，201语言 |

### 7.2 性能超越里程碑

- **Qwen2**: 首次在多项基准超越Llama-3
- **Qwen2.5**: 以1/5参数超越Llama-3-405B
- **Qwen3**: 超越GPT-4o、DeepSeek-V3等闭源模型
- **Qwen3.5**: 原生多模态超越分离式架构

---

## 8. 发展趋势分析

### 8.1 数据Scaling持续

从Qwen1到Qwen3，训练数据增长了**12倍**（3T→36T），数据质量与规模并重。

### 8.2 架构效率优先

- Qwen2引入GQA降低KV缓存
- Qwen3采用MoE降低激活参数
- Qwen3.5使用Gated DeltaNet提升效率

### 8.3 多模态原生化

从Qwen2-VL分离式架构，到Qwen3.5原生统一架构，多模态能力不断增强。

### 8.4 Agent能力深化

从基础工具调用，到原生多模态Agent，Qwen系列在Agent方向持续深化。

---

## 总结

Qwen系列从2023年9月到2026年2月的演进，展现了中国大模型技术的快速发展：

### 核心成就

1. **数据工程领先**: 从3T到36T，数据Scaling持续
2. **架构创新不断**: GQA、MoE、Gated DeltaNet持续迭代
3. **多语言覆盖广**: 从双语到201种语言
4. **多模态原生**: 从分离到统一的范式转变
5. **开源生态完善**: Apache 2.0，全尺寸开源

### 技术启示

- **稳健迭代**: Qwen1→1.5→2的渐进式升级
- **全面突破**: Qwen2.5在多个维度同时提升
- **架构革新**: Qwen3的双模式统一和Qwen3.5的原生多模态

Qwen系列的发展历程，为开源大模型的演进提供了宝贵的参考路径。
