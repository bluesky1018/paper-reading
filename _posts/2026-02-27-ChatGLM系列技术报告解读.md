---
layout: post
title: "ChatGLM系列技术报告深度解读"
date: 2026-02-27 00:25:00 +0800
categories: paper-reading chatglm glm zhipu
---

## 论文基本信息

> **论文**: ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools  
> **arXiv**: [2406.12793](https://arxiv.org/abs/2406.12793)  
> **发布时间**: 2024年6月18日  
> **作者**: Team GLM (智谱AI团队)

---

## 1. 概述

本文全面介绍了ChatGLM系列大语言模型的演进历程，从GLM-130B到最新的GLM-4系列。重点介绍了GLM-4语言系列（GLM-4、GLM-4-Air、GLM-4-9B）的技术细节和性能表现。

---

## 2. ChatGLM演进历程

### 2.1 版本时间线

```
2022.10  GLM-130B     → 开源双语130B基础模型
2023.03  ChatGLM-6B   → 6B对话模型（3代）
2024.06  GLM-4系列    → 最新一代：GLM-4/GLM-4-Air/GLM-4-9B
```

### 2.2 各代特点

| 版本 | 发布时间 | 参数量 | 核心特点 |
|------|----------|--------|----------|
| **ChatGLM-6B** | 2023.03 | 6B | 首代开源对话模型 |
| **ChatGLM2-6B** | 2023.06 | 6B | 32K上下文，FlashAttention |
| **ChatGLM3-6B** | 2023.10 | 6B | 基础模型+工具调用 |
| **GLM-4** | 2024.06 | 未公开 | 10T tokens训练 |
| **GLM-4-9B** | 2024.06 | 9B | 开源版本，128K/1M上下文 |

---

## 3. GLM-4系列详解

### 3.1 训练数据

| 参数 | 详情 |
|------|------|
| **数据规模** | **10万亿 (10T) tokens** |
| **主要语言** | 中英文为主 |
| **其他语言** | 24种语言的小规模语料 |
| **优化目标** | 主要针对中英文使用场景 |

### 3.2 对齐策略

**多阶段后训练流程**:

```
阶段1: 监督微调 (SFT)
├── 高质量指令数据
├── 多轮对话数据
└── 安全对齐数据

阶段2: 人类反馈强化学习 (RLHF)
├── 奖励模型训练
├── PPO优化
└── 人类偏好对齐
```

### 3.3 模型系列

| 模型 | 定位 | 上下文 | 特点 |
|------|------|--------|------|
| **GLM-4** | 旗舰版 | 128K | 最强性能，API服务 |
| **GLM-4-Air** | 高效版 | 未公开 | 平衡性能与效率 |
| **GLM-4-9B** | 开源版 | 128K/1M | 开源可商用 |

---

## 4. 核心能力

### 4.1 对标GPT-4

GLM-4在以下方面**匹敌或超越** GPT-4：

| 评测维度 | 评测集 | GLM-4 vs GPT-4 |
|----------|--------|----------------|
| **通用能力** | MMLU, GSM8K, MATH, BBH | 匹敌或超越 |
| **指令遵循** | IFEval | 接近GPT-4-Turbo |
| **长上下文** | 128K任务 | 匹敌GPT-4 Turbo (128K) |
| **长上下文** | 长文本 | 匹敌Claude 3 |
| **中文对齐** | AlignBench | **超越** GPT-4 |

### 4.2 GLM-4 All Tools

**工具调用能力**:

| 工具类型 | 能力描述 |
|----------|----------|
| **Web Browser** | 自动浏览网页获取信息 |
| **Python Interpreter** | 执行Python代码解决数学问题 |
| **Text-to-Image** | 调用文生图模型 |
| **User-defined Functions** | 调用用户自定义函数 |

**实际应用表现**:
- 网页浏览获取在线信息：匹敌或超越GPT-4 All Tools
- Python解释器解决数学问题：匹敌或超越GPT-4 All Tools

---

## 5. 开源生态

### 5.1 开源模型矩阵

| 模型 | 参数量 | 上下文 | 特点 | 下载量(2023) |
|------|--------|--------|------|--------------|
| **ChatGLM-6B** | 6B | 2K/8K | 首代开源 | - |
| **ChatGLM2-6B** | 6B | 32K | 长上下文 | - |
| **ChatGLM3-6B** | 6B | 8K/32K | 工具调用 | - |
| **GLM-4-9B** | 9B | 128K/1M | 最新开源 | - |
| **GLM-4V-9B** | 9B | 8K | 视觉语言 | - |
| **CodeGeeX** | - | - | 代码生成 | - |
| **WebGLM** | - | - | 网页增强 | - |

**2023年Hugging Face下载量**: 超过1000万次

### 5.2 配套基准测试

智谱团队还开发了多个开源评测基准：

| 基准 | 用途 |
|------|------|
| **AgentBench** | 评测LLM作为Agent的能力 |
| **LongBench** | 评测长上下文处理能力 |
| **AlignBench** | 评测中文对齐质量 |
| **HumanEval-X** | 评测代码生成能力 |

---

## 6. 与GPT-4全面对比

| 维度 | GLM-4 | GPT-4 | 对比结果 |
|------|-------|-------|----------|
| **MMLU** | 高分 | 高分 | 匹敌 |
| **GSM8K** | 高分 | 高分 | 匹敌 |
| **MATH** | 高分 | 高分 | 匹敌 |
| **BBH** | 高分 | 高分 | 匹敌 |
| **GPQA** | 高分 | 高分 | 匹敌 |
| **HumanEval** | 高分 | 高分 | 匹敌 |
| **IFEval** | 接近 | Turbo水平 | 接近 |
| **长上下文(128K)** | 匹敌 | Turbo水平 | 匹敌 |
| **AlignBench(中文)** | **超越** | 落后 | 领先 |

---

## 总结

ChatGLM系列展现了智谱AI在大模型领域的技术积累：

1. **从GLM-130B到GLM-4的演进**: 持续迭代优化
2. **10T tokens训练数据**: 大规模高质量数据
3. **多阶段对齐**: SFT+RLHF确保高质量对齐
4. **工具调用**: GLM-4 All Tools匹敌GPT-4
5. **中文优势**: AlignBench超越GPT-4
6. **开源生态**: 全系列开源，社区活跃

ChatGLM系列是中国大模型开源的标杆，为国内外研究者和开发者提供了宝贵资源。
